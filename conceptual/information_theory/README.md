# Information theory

* [Kullback-Leibler Divergence(KL Divergence, Relative entropy)](https://www.zhihu.com/question/41252833), [backup](2.png)
* [Jensen-Shannon divergence](http://blog.csdn.net/victoriaw/article/details/56494922), [backup](3.html)
* [Difference between KL and JS](https://www.quora.com/Why-isnt-the-Jensen-Shannon-divergence-used-more-often-than-the-Kullback-Leibler-since-JS-is-symmetric-thus-possibly-a-better-indicator-of-distance), [backup](1.html)
* [Difference among Bhattacharyya distance, Hellinger distance and KL divergence](https://stats.stackexchange.com/questions/130432/differences-between-bhattacharyya-distance-and-kl-divergence)