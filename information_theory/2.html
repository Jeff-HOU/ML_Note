<!doctype html>
<html lang="zh" data-reactroot="" data-reactid="1" data-react-checksum="2125236051"><head data-reactid="2"><meta charset="utf-8" data-reactid="3"/><title data-react-helmet="true" data-reactid="4">如何通俗的解释交叉熵与相对熵? - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1" data-reactid="5"/><meta name="renderer" content="webkit" data-reactid="6"/><meta name="force-rendering" content="webkit" data-reactid="7"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" data-reactid="8"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg" data-reactid="9"/><meta data-react-helmet="true" name="apple-itunes-app" content="app-id=432274380, app-argument=zhihu://question/41252833" data-reactid="10"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico" data-reactid="11"/><link rel="dns-prefetch" href="//static.zhihu.com" data-reactid="12"/><link rel="dns-prefetch" href="//pic1.zhihu.com" data-reactid="13"/><link rel="dns-prefetch" href="//pic2.zhihu.com" data-reactid="14"/><link rel="dns-prefetch" href="//pic3.zhihu.com" data-reactid="15"/><link rel="dns-prefetch" href="//pic4.zhihu.com" data-reactid="16"/><link href="https://static.zhihu.com/heifetz/main.app.60773bcb05ccf3598b91.css" rel="stylesheet" data-reactid="17"/></head><body class="Entry-body Body--isAppleDevice" data-reactid="18"><div id="root" data-reactid="19"><div><div class="LoadingBar"></div><div><header role="banner" class="Sticky AppHeader" data-za-module="TopNavBar"><div class="AppHeader-inner"><a href="/" aria-label="知乎"><svg viewBox="0 0 200 91" class="Icon Icon--logo" style="fill:#0f88eb;height:30px;width:64px;" width="64" height="30" aria-hidden="true"><title></title><g><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"/></g></svg></a><nav role="navigation" class="AppHeader-nav"><a class="AppHeader-navItem" href="/">首页</a><a class="AppHeader-navItem" href="/explore">发现</a><a class="AppHeader-navItem" href="/topic">话题</a></nav><div class="SearchBar" role="search"><div class="SearchBar-toolWrapper"><form class="SearchBar-tool"><div><div class="Popover"><div class="SearchBar-input Input-wrapper Input-wrapper--grey"><input type="text" maxlength="100" value="" autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete-16706-70327--1" id="Popover-16707-86595-toggle" aria-haspopup="true" aria-owns="Popover-16707-86595-content" class="Input" placeholder="搜索你感兴趣的内容…"/><div class="Input-after"><button class="Button SearchBar-searchIcon Button--primary" aria-label="搜索" type="button"><svg viewBox="0 0 16 16" class="Icon Icon--search" style="height:16px;width:16px;" width="16" height="16" aria-hidden="true"><title></title><g><path d="M12.054 10.864c.887-1.14 1.42-2.57 1.42-4.127C13.474 3.017 10.457 0 6.737 0S0 3.016 0 6.737c0 3.72 3.016 6.737 6.737 6.737 1.556 0 2.985-.533 4.127-1.42l3.103 3.104c.765.46 1.705-.37 1.19-1.19l-3.103-3.104zm-5.317.925c-2.786 0-5.053-2.267-5.053-5.053S3.95 1.684 6.737 1.684 11.79 3.95 11.79 6.737 9.522 11.79 6.736 11.79z"/></g></svg></button></div></div></div></div></form></div><button class="Button QuestionAskButton SearchBar-askButton Button--primary Button--blue" type="button">提问</button></div><div class="AppHeader-userInfo"><button class="Button PushNotifications-icon AppHeader-notifications Button--plain" type="button"><svg viewBox="0 0 20 22" class="Icon Icon--news" style="height:20px;width:20px;" width="20" height="20" aria-hidden="true"><title></title><g><path d="M2.502 14.08C3.1 10.64 2 3 8.202 1.62 8.307.697 9.08 0 10 0s1.694.697 1.797 1.62C18 3 16.903 10.64 17.497 14.076c.106 1.102.736 1.855 1.7 2.108.527.142.868.66.793 1.206-.075.546-.542.95-1.09.943H1.1C.55 18.34.084 17.936.01 17.39c-.075-.547.266-1.064.794-1.206.963-.253 1.698-1.137 1.698-2.104zM10 22c-1.417.003-2.602-1.086-2.73-2.51-.004-.062.02-.124.063-.17.043-.045.104-.07.166-.07h5c.063 0 .124.025.167.07.044.046.067.108.063.17-.128 1.424-1.313 2.513-2.73 2.51z" /></g></svg></button><button class="Button Messages-icon AppHeader-messages Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--message" style="height:20px;width:20px;" width="20" height="20" aria-hidden="true"><title></title><g><path d="M9 0C3.394 0 0 4.13 0 8c0 1.654.522 3.763 2.014 5.566.314.292.518.82.454 1.17-.165 1.488-.842 1.905-.842 1.905-.328.332.105.67.588.582 1.112-.2 2.07-.58 3.526-1.122.4-.202.464-.147.78-.078C11.524 17.764 18 14 18 8c0-3.665-3.43-8-9-8z"/><path d="M19.14 9.628c.758.988.86 2.01.86 3.15 0 1.195-.62 3.11-1.368 3.938-.21.23-.354.467-.308.722.12 1.073.614 1.5.614 1.5.237.24-.188.563-.537.5-.802-.145-1.494-.42-2.545-.81-.29-.146-.336-.106-.563-.057-2.043.712-4.398.476-6.083-.926 5.964-.524 8.726-3.03 9.93-8.016z"/></g></svg></button><div class="AppHeader-profile"><button class="Button AppHeader-profileEntry Button--plain" type="button"><img class="Avatar AppHeader-profileAvatar" width="30" height="30" src="https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_is.jpg" srcset="https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_im.jpg 2x"/></button></div></div></div></header></div><main role="main" class="App-main"><div itemscope="" itemtype="http://schema.org/Question"><meta itemprop="name" content="如何通俗的解释交叉熵与相对熵?"/><meta itemprop="url" content="https://www.zhihu.com/question/41252833"/><meta itemprop="keywords" content="数学,机器学习,信息论"/><meta itemprop="answerCount" content="5"/><meta itemprop="commentCount" content="0"/><meta itemprop="dateCreated" content="2016-03-11T05:00:08.000Z"/><meta itemprop="dateModified" content="2016-03-11T05:00:08.000Z"/><meta itemprop="zhihu:visitsCount"/><meta itemprop="zhihu:followerCount" content="396"/><div><div class="QuestionStatus"></div><div class="QuestionHeader"><div class="QuestionHeader-content"><div class="QuestionHeader-main"><div class="QuestionHeader-topics"><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19554091"><div class="Popover"><div id="Popover-16712-17619-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16712-17619-content">数学</div></div></a></span></div><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19559450"><div class="Popover"><div id="Popover-16712-6781-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16712-6781-content">机器学习</div></div></a></span></div><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19612134"><div class="Popover"><div id="Popover-16713-23668-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16713-23668-content">信息论</div></div></a></span></div></div><h1 class="QuestionHeader-title">如何通俗的解释交叉熵与相对熵?</h1><div class="QuestionHeader-detail"><div class="QuestionRichText QuestionRichText--expandable QuestionRichText--collapsed"><div><span class="RichText" itemprop="text">如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？</span><button class="Button QuestionRichText-more Button--plain" type="button">显示全部<svg viewBox="0 0 10 6" class="Icon QuestionRichText-more-icon Icon--arrow" style="height:16px;width:10px;" width="10" height="16" aria-hidden="true"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"/></g></svg></button></div></div></div></div><div class="QuestionHeader-side"><div class="QuestionHeader-follow-status"><div class="QuestionFollowStatus"><div class="NumberBoard QuestionFollowStatus-counts"><button class="Button NumberBoard-item Button--plain" type="button"><div class="NumberBoard-name">关注者</div><div class="NumberBoard-value">396</div></button><div class="NumberBoard-divider"></div><div class="NumberBoard-item"><div class="NumberBoard-name">被浏览</div><div class="NumberBoard-value">25804</div></div></div></div></div></div></div><div class="QuestionHeader-footer"><div class="QuestionHeader-footer-inner"><div class="QuestionHeader-main QuestionHeader-footer-main"><div class="QuestionHeaderActions"><div class="QuestionHeader-Comment"><button class="Button Button--plain" type="button"><svg viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--comment Icon--left" style="height:15px;width:20px;" width="20" height="15" aria-hidden="true"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"/></g></svg>添加评论</button></div><div class="Popover ShareMenu"><div id="Popover-16715-25636-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16715-25636-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--share Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"/></g></svg>分享</button></div></div><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"/></g></svg>邀请回答</button><button class="Button Button--plain" type="button"><svg viewBox="0 0 18 20" class="Icon Icon--report Icon--left" style="height:16px;width:11px;" width="11" height="16" aria-hidden="true"><title></title><g><path d="M16.947 1.13c-.633.135-3.927.638-5.697.384-3.133-.45-4.776-2.54-9.95-.888C.305 1.04.025 1.664.025 2.646L0 18.807c0 .3.1.54.304.718.195.202.438.304.73.304.275 0 .52-.102.73-.304.202-.18.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V1.964c0-.6-.42-.972-1.053-.835z"/></g></svg>举报</button><div class="Popover"><button class="Button Button--plain" type="button" id="Popover-16716-72998-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16716-72998-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" style="height:16px;width:14px;" width="14" height="16" aria-hidden="true"><title></title><g><g><circle cx="2" cy="2" r="2"/><circle cx="9" cy="2" r="2"/><circle cx="16" cy="2" r="2"/></g></g></svg></button></div></div><div class="QuestionHeader-actions"></div></div><div class="QuestionHeader-side"><div class="QuestionButtonGroup"><button class="Button Button--primary Button--blue" type="button">关注问题</button><button class="Button Button--blue" type="button"><svg viewBox="0 0 12 12" class="Icon Button-icon Icon--modify" style="height:16px;width:14px;" width="14" height="16" aria-hidden="true"><title></title><g><path d="M.423 10.32L0 12l1.667-.474 1.55-.44-2.4-2.33-.394 1.564zM10.153.233c-.327-.318-.85-.31-1.17.018l-.793.817 2.49 2.414.792-.814c.318-.328.312-.852-.017-1.17l-1.3-1.263zM3.84 10.536L1.35 8.122l6.265-6.46 2.49 2.414-6.265 6.46z" fill-rule="evenodd"/></g></svg>写回答</button></div></div></div></div></div><div><div><div class="Sticky"></div></div></div></div><div class="Question-main"><div class="Question-mainColumn"><div><div id="QuestionAnswers-answers" class="QuestionAnswers-answers"><div class="Card"><div class="List"><div class="List-header"><h4 class="List-headerText"><span>5 个回答</span></h4><div class="List-headerOptions"><div class="Popover"><button class="Button Select-button Select-plainButton Button--plain" role="combobox" aria-expanded="false" type="button" id="Popover-16719-29682-toggle" aria-haspopup="true" aria-owns="Popover-16719-29682-content">默认排序<svg viewBox="0 0 8 13" class="Icon Select-arrow Icon--select" style="height:16px;width:8px;" width="8" height="16" aria-hidden="true"><title></title><g><path d="M4 11.183L1.284 8.218c-.293-.29-.77-.29-1.064 0-.293.29-.293.76 0 1.052l3.25 3.512c.292.29.768.29 1.062 0L7.78 9.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.064 0L4 11.182zM4 1.818L1.284 4.782c-.293.29-.77.29-1.064 0-.293-.29-.293-.76 0-1.052L3.47.218c.292-.29.768-.29 1.062 0L7.78 3.73c.293.29.293.76 0 1.052-.295.29-.77.29-1.064 0L4 1.82z"/></g></svg></button></div></div></div><div><div class="List-item"><div class="ContentItem AnswerItem" name="108777563" itemprop="acceptedAnswer" itemtype="http://schema.org/Answer" itemscope=""><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="Noriko Oshima"/><meta itemprop="image" content="https://pic3.zhimg.com/7cf43c65cbe2780071ed935e569d519e_is.jpg"/><meta itemprop="url" content="https://www.zhihu.com/people/do-cre"/><meta itemprop="zhihu:followerCount" content="119"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover-16722-80315-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16722-80315-content"><a class="UserLink-link" href="/people/do-cre"><img class="Avatar AuthorInfo-avatar" width="38" height="38" src="https://pic3.zhimg.com/7cf43c65cbe2780071ed935e569d519e_xs.jpg" srcset="https://pic3.zhimg.com/7cf43c65cbe2780071ed935e569d519e_l.jpg 2x" alt="Noriko Oshima"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover-16723-37933-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16723-37933-content"><a class="UserLink-link" href="/people/do-cre">Noriko Oshima</a></div></div></span></div><div class="AuthorInfo-detail"></div></div></div><div class="AnswerItem-extraInfo"><span class="Voters"><button class="Button Button--plain" type="button">270 人赞同了该回答</button></span></div></div></div><meta itemprop="image" content=""/><meta itemprop="upvoteCount" content="270"/><meta itemprop="url" content="https://www.zhihu.com/question/41252833/answer/108777563"/><meta itemprop="dateCreated" content="2016-07-01T04:11:12.000Z"/><meta itemprop="dateModified" content="2016-07-01T04:13:55.000Z"/><meta itemprop="commentCount" content="27"/><div class="RichContent RichContent--unescapable"><div class="RichContent-inner"><span class="RichText CopyrightRichText-richText" itemprop="text">熵的本质是香农信息量(<img src="https://www.zhihu.com/equation?tex=log%5Cfrac%7B1%7D%7Bp%7D+" alt="log\frac{1}{p} " eeimg="1">)的期望。<br><br>现有关于样本集的2个概率分布p和q，其中p为真实分布，q非真实分布。按照真实分布p来衡量识别一个样本的所需要的编码长度的期望(即平均编码长度)为：H(p)=<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%7D%5E%7B%7D+p%28i%29%2Alog%5Cfrac%7B1%7D%7Bp%28i%29%7D+" alt="\sum_{i}^{} p(i)*log\frac{1}{p(i)} " eeimg="1">。如果使用错误分布q来表示来自真实分布p的平均编码长度，则应该是：H(p,q)=<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%7D%5E%7B%7D+p%28i%29%2Alog%5Cfrac%7B1%7D%7Bq%28i%29%7D+" alt="\sum_{i}^{} p(i)*log\frac{1}{q(i)} " eeimg="1">。因为用q来编码的样本来自分布p，所以期望H(p,q)中概率是p(i)。H(p,q)我们称之为“交叉熵”。<br><br>比如含有4个字母(A,B,C,D)的数据集中，真实分布p=(1/2, 1/2, 0, 0)，即A和B出现的概率均为1/2，C和D出现的概率都为0。计算H(p)为1，即只需要1位编码即可识别A和B。如果使用分布Q=(1/4, 1/4, 1/4, 1/4)来编码则得到H(p,q)=2，即需要2位编码来识别A和B(当然还有C和D，尽管C和D并不会出现，因为真实分布p中C和D出现的概率为0，这里就钦定概率为0的事件不会发生啦)。<br><br>可以看到上例中根据非真实分布q得到的平均编码长度H(p,q)大于根据真实分布p得到的平均编码长度H(p)。事实上，根据<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Gibbs%2527_inequality" class=" wrap external" target="_blank" rel="nofollow noreferrer">Gibbs' inequality<i class="icon-external"></i></a>可知，H(p,q)&gt;=H(p)恒成立，当q为真实分布p时取等号。我们将由q得到的平均编码长度比由p得到的平均编码长度多出的bit数称为“相对熵”：D(p||q)=H(p,q)-H(p)=<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%7D%5E%7B%7D+p%28i%29%2Alog%5Cfrac%7Bp%28i%29%7D%7Bq%28i%29%7D+" alt="\sum_{i}^{} p(i)*log\frac{p(i)}{q(i)} " eeimg="1">，其又被称为KL散度(Kullback–Leibler divergence，KLD) <a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kullback%25E2%2580%2593Leibler_divergence" class=" wrap external" target="_blank" rel="nofollow noreferrer">Kullback–Leibler divergence<i class="icon-external"></i></a>。它表示2个函数或概率分布的差异性：差异越大则相对熵越大，差异越小则相对熵越小，特别地，若2者相同则熵为0。注意，KL散度的非对称性。<br><br>比如TD-IDF算法就可以理解为相对熵的应用：词频在整个语料库的分布与词频在具体文档中分布之间的差异性。<br><br>交叉熵可在神经网络(机器学习)中作为损失函数，p表示真实标记的分布，q则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量p与q的相似性。交叉熵作为损失函数还有一个好处是使用sigmoid函数在梯度下降时能避免均方误差损失函数学习速率降低的问题，因为学习速率可以被输出的误差所控制。<br><br>PS：通常“相对熵”也可称为“交叉熵”，因为真实分布p是固定的，D(p||q)由H(p,q)决定。当然也有特殊情况，彼时2者须区别对待。</span></div><div class="ContentItem-time"><a target="_blank" href="/question/41252833/answer/108777563"><span data-tooltip="发布于 2016-07-01">编辑于 2016-07-01</span></a></div><div class="ContentItem-actions"><span><button class="Button VoteButton VoteButton--up" aria-label="赞同" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg>270</button><button class="Button VoteButton VoteButton--down" aria-label="反对" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--comment Icon--left" style="height:16px;width:12px;" width="12" height="16" aria-hidden="true"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"/></g></svg>27 条评论</button><div class="Popover ShareMenu ContentItem-action"><div id="Popover-16726-84152-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16726-84152-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--share Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"/></g></svg>分享</button></div></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"/></g></svg>收藏</button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" style="height:16px;width:14px;" aria-hidden="true"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"/></g></svg>感谢</button><div class="Popover ContentItem-action"><button class="Button Button--plain" type="button" id="Popover-16726-94478-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16726-94478-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" style="height:16px;width:14px;" width="14" height="16" aria-hidden="true"><title></title><g><g><circle cx="2" cy="2" r="2"/><circle cx="9" cy="2" r="2"/><circle cx="16" cy="2" r="2"/></g></g></svg></button></div><button class="Button ContentItem-action ContentItem-rightButton Button--plain" type="button">收起<svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon is-active Icon--arrow" style="height:16px;width:10px;" width="10" height="16" aria-hidden="true"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"/></g></svg></button></div></div></div></div><div class="List-item"><div class="ContentItem AnswerItem" name="141598211" itemprop="suggestedAnswer" itemtype="http://schema.org/Answer" itemscope=""><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="Agenter"/><meta itemprop="image" content="https://pic2.zhimg.com/648cadddeccb1697f74af886d1838e69_is.jpg"/><meta itemprop="url" content="https://www.zhihu.com/people/xing-xiao-xiao-33"/><meta itemprop="zhihu:followerCount" content="14"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover-16729-5856-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16729-5856-content"><a class="UserLink-link" href="/people/xing-xiao-xiao-33"><img class="Avatar AuthorInfo-avatar" width="38" height="38" src="https://pic2.zhimg.com/648cadddeccb1697f74af886d1838e69_xs.jpg" srcset="https://pic2.zhimg.com/648cadddeccb1697f74af886d1838e69_l.jpg 2x" alt="Agenter"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover-16730-33880-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16730-33880-content"><a class="UserLink-link" href="/people/xing-xiao-xiao-33">Agenter</a></div></div></span></div><div class="AuthorInfo-detail"><div class="RichText AuthorInfo-badge">图像视觉算法和美剧爱好者</div></div></div></div><div class="AnswerItem-extraInfo"><span class="Voters"><button class="Button Button--plain" type="button">27 人赞同了该回答</button></span></div></div></div><meta itemprop="image" content=""/><meta itemprop="upvoteCount" content="27"/><meta itemprop="url" content="https://www.zhihu.com/question/41252833/answer/141598211"/><meta itemprop="dateCreated" content="2017-01-18T08:44:08.000Z"/><meta itemprop="dateModified" content="2017-01-18T10:16:04.000Z"/><meta itemprop="commentCount" content="1"/><div class="RichContent RichContent--unescapable"><div class="RichContent-inner"><span class="RichText CopyrightRichText-richText" itemprop="text"><p>仅从机器学习的角度讨论这个问题。</p><p><b>相对熵（relative entropy）</b>就是KL散度（Kullback–Leibler divergence），用于衡量两个概率分布之间的差异。</p><p>对于两个概率分布<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" eeimg="1">和<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="q(x)" eeimg="1"> ，其相对熵的计算公式为：</p><img src="https://www.zhihu.com/equation?tex=%5Ctt+KL%5Cit%28p%5Cparallel+q%29%3D-%5Cint+p%28x%29%5Cln+q%28x%29+dx+-%28-%5Cint+p%28x%29%5Cln+p%28x%29+dx%29" alt="\tt KL\it(p\parallel q)=-\int p(x)\ln q(x) dx -(-\int p(x)\ln p(x) dx)" eeimg="1"><p>注意：由于<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" eeimg="1"> 和<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="q(x)" eeimg="1"> 在公式中的地位不是相等的，所以<img src="https://www.zhihu.com/equation?tex=%5Ctt+KL+%5Cit%28p%5Cparallel+q%29%5Cnot%5Cequiv+%5Ctt+KL+%5Cit+%28q%5Cparallel+p%29" alt="\tt KL \it(p\parallel q)\not\equiv \tt KL \it (q\parallel p)" eeimg="1">.</p><p>相对熵的特点，是只有<img src="https://www.zhihu.com/equation?tex=p%28x%29%3Dq%28x%29" alt="p(x)=q(x)" eeimg="1"> 时，其值为0。若<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" eeimg="1"> 和<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="q(x)" eeimg="1"> 略有差异，其值就会大于0。其证明利用了负对数函数（<img src="https://www.zhihu.com/equation?tex=-%5Cln+x" alt="-\ln x" eeimg="1"> ）是严格凸函数（strictly convex function）的性质。具体可以参考<i>PRML</i> 1.6.1 Relative entropy and mutual information.</p><p>相对熵公式的前半部分<img src="https://www.zhihu.com/equation?tex=-%5Cint+p%28x%29%5Cln+q%28x%29dx" alt="-\int p(x)\ln q(x)dx" eeimg="1"> 就是<b>交叉熵（cross entropy）。</b></p><p>若<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" eeimg="1"> 是数据的真实概率分布，<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="q(x)" eeimg="1"> 是由数据计算得到的概率分布。机器学习的目的就是希望<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="q(x)" eeimg="1">尽可能地逼近甚至等于<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" eeimg="1"> ，从而使得相对熵接近最小值0. 由于真实的概率分布是固定的，相对熵公式的后半部分<img src="https://www.zhihu.com/equation?tex=%28-%5Cint+p%28x%29%5Cln+p%28x%29+dx%29" alt="(-\int p(x)\ln p(x) dx)" eeimg="1"> 就成了一个常数。那么相对熵达到最小值的时候，也意味着交叉熵达到了最小值。对<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="q(x)" eeimg="1"> 的优化就等效于求交叉熵的最小值。另外，对交叉熵求最小值，也等效于求最大似然估计（maximum likelihood estimation）。具体可以参考<i>Deep Learning</i> 5.5 Maximum Likelihood Estimation.</p></span></div><div class="ContentItem-time"><a target="_blank" href="/question/41252833/answer/141598211"><span data-tooltip="发布于 2017-01-18">编辑于 2017-01-18</span></a></div><div class="ContentItem-actions"><span><button class="Button VoteButton VoteButton--up" aria-label="赞同" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg>27</button><button class="Button VoteButton VoteButton--down" aria-label="反对" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--comment Icon--left" style="height:16px;width:12px;" width="12" height="16" aria-hidden="true"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"/></g></svg>1 条评论</button><div class="Popover ShareMenu ContentItem-action"><div id="Popover-16733-74824-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16733-74824-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--share Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"/></g></svg>分享</button></div></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"/></g></svg>收藏</button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" style="height:16px;width:14px;" aria-hidden="true"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"/></g></svg>感谢</button><div class="Popover ContentItem-action"><button class="Button Button--plain" type="button" id="Popover-16734-58175-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-16734-58175-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" style="height:16px;width:14px;" width="14" height="16" aria-hidden="true"><title></title><g><g><circle cx="2" cy="2" r="2"/><circle cx="9" cy="2" r="2"/><circle cx="16" cy="2" r="2"/></g></g></svg></button></div><button class="Button ContentItem-action ContentItem-rightButton Button--plain" type="button">收起<svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon is-active Icon--arrow" style="height:16px;width:10px;" width="10" height="16" aria-hidden="true"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"/></g></svg></button></div></div></div></div></div></div></div><div class="Card"><button class="Button QuestionMainAction" type="button">更多</button></div></div><div class="CollapsedAnswers-bar"><button class="Button Button--plain" type="button">2 个回答被折叠</button>（<a class="Button Button--plain" target="_blank" type="button" href="/question/20120168">为什么？</a>）</div><div class="Card QuestionAnswers-answerAdd"><div class="AnswerAdd"><div class="AnswerAdd-header"><div class="AuthorInfo AnswerAdd-info" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="侯祥云"/><meta itemprop="image" content="https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_is.jpg"/><meta itemprop="url" content="https://www.zhihu.com/people/houkaijun"/><meta itemprop="zhihu:followerCount" content="0"/><span class="UserLink AuthorInfo-avatarWrapper"><img class="Avatar AuthorInfo-avatar" width="38" height="38" src="https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_xs.jpg" srcset="https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_l.jpg 2x" alt="侯祥云"/></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name">侯祥云</span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><button class="Button ModifyButton AnswerAdd-topicBiosButton Button--link" type="button"><svg viewBox="0 0 12 12" class="Icon ModifyButton-icon Icon--modify" style="height:16px;width:12px;" width="12" height="16" aria-hidden="true"><title></title><g><path d="M.423 10.32L0 12l1.667-.474 1.55-.44-2.4-2.33-.394 1.564zM10.153.233c-.327-.318-.85-.31-1.17.018l-.793.817 2.49 2.414.792-.814c.318-.328.312-.852-.017-1.17l-1.3-1.263zM3.84 10.536L1.35 8.122l6.265-6.46 2.49 2.414-6.265 6.46z" fill-rule="evenodd"/></g></svg>编辑话题经验</button></div></div></div></div><button class="Button AnswerAdd-toggleAnonymous Button--plain" type="button">使用匿名身份回答</button></div><form class="AnswerForm" novalidate=""><div><div class="Sticky AnswerForm-footer AnswerForm-footer--hidden is-bottom"><div class="AnswerForm-status"></div><div class="AnswerForm-footerRight"><div class="Popover"><button class="Button Select-button Select-plainButton Button--plain" role="combobox" aria-expanded="false" type="button" id="Popover-16739-74472-toggle" aria-haspopup="true" aria-owns="Popover-16739-74472-content">允许规范转载<svg viewBox="0 0 8 13" class="Icon Select-arrow Icon--select" style="height:16px;width:8px;" width="8" height="16" aria-hidden="true"><title></title><g><path d="M4 11.183L1.284 8.218c-.293-.29-.77-.29-1.064 0-.293.29-.293.76 0 1.052l3.25 3.512c.292.29.768.29 1.062 0L7.78 9.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.064 0L4 11.182zM4 1.818L1.284 4.782c-.293.29-.77.29-1.064 0-.293-.29-.293-.76 0-1.052L3.47.218c.292-.29.768-.29 1.062 0L7.78 3.73c.293.29.293.76 0 1.052-.295.29-.77.29-1.064 0L4 1.82z"/></g></svg></button></div><button class="Button AnswerForm-submit Button--primary Button--blue" type="button">提交回答</button></div></div></div></form></div></div></div></div><div class="Question-sideColumn Question-sideColumn--sticky"><div><div class="Sticky"></div></div></div></div></div></main></div></div><div id="data" style="display:none;" data-state="{&quot;loading&quot;:{&quot;global&quot;:{&quot;count&quot;:0},&quot;local&quot;:{&quot;token/&quot;:false,&quot;currentUser/get/&quot;:false,&quot;env/getExperiments/&quot;:false,&quot;config/getAppConfig/&quot;:false,&quot;question/get/&quot;:false,&quot;question/getAnswers/41252833&quot;:false}},&quot;entities&quot;:{&quot;users&quot;:{&quot;houkaijun&quot;:{&quot;uid&quot;:680518491698761700,&quot;followNotificationsCount&quot;:0,&quot;adType&quot;:&quot;normal&quot;,&quot;showSinaWeibo&quot;:false,&quot;editorInfo&quot;:[],&quot;isBindPhone&quot;:true,&quot;accountStatus&quot;:[],&quot;isForceRenamed&quot;:false,&quot;id&quot;:&quot;87940d8802edbc8d1d0ec6ca7a2b4e19&quot;,&quot;messagesCount&quot;:0,&quot;headline&quot;:&quot;&quot;,&quot;visitsCount&quot;:39,&quot;isAdvertiser&quot;:false,&quot;isBindSina&quot;:false,&quot;favoritedCount&quot;:0,&quot;isOrg&quot;:false,&quot;followerCount&quot;:0,&quot;employments&quot;:[],&quot;articlesCount&quot;:0,&quot;type&quot;:&quot;people&quot;,&quot;caEnabled&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_{size}.jpg&quot;,&quot;draftCount&quot;:0,&quot;description&quot;:&quot;&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/1047945e738bdbf036f6aabb85a1a250_is.jpg&quot;,&quot;isActive&quot;:1455028251,&quot;answerCount&quot;:0,&quot;userType&quot;:&quot;people&quot;,&quot;coverUrl&quot;:&quot;&quot;,&quot;defaultNotificationsCount&quot;:0,&quot;educations&quot;:[],&quot;urlToken&quot;:&quot;houkaijun&quot;,&quot;canEditTopic&quot;:false,&quot;name&quot;:&quot;侯祥云&quot;,&quot;locations&quot;:[],&quot;badge&quot;:[],&quot;availableMessageTypes&quot;:[&quot;common&quot;],&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/87940d8802edbc8d1d0ec6ca7a2b4e19&quot;,&quot;renamedFullname&quot;:&quot;&quot;,&quot;voteThankNotificationsCount&quot;:0,&quot;thankedCount&quot;:0,&quot;gender&quot;:1,&quot;favoriteCount&quot;:9}},&quot;questions&quot;:{&quot;41252833&quot;:{&quot;status&quot;:{&quot;isLocked&quot;:false,&quot;isClose&quot;:false,&quot;isEvaluate&quot;:false,&quot;isSuggest&quot;:false},&quot;relationship&quot;:{&quot;concernedFollowers&quot;:[],&quot;isAnonymous&quot;:false,&quot;canLock&quot;:false,&quot;isFollowing&quot;:false,&quot;isAuthor&quot;:false,&quot;canCollapseAnswers&quot;:false,&quot;canStickAnswers&quot;:false},&quot;isMuted&quot;:false,&quot;topics&quot;:[{&quot;introduction&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/3dc1abe04_is.jpg&quot;,&quot;name&quot;:&quot;数学&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19554091&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;id&quot;:&quot;19554091&quot;},{&quot;introduction&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;计算机\&quot;&gt;计算机&lt;/a&gt;可以自动“&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E5%AD%A6%E4%B9%A0\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;学习\&quot;&gt;学习&lt;/a&gt;”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%AE%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;推论\&quot;&gt;推论&lt;/a&gt;问题属于&lt;a href=\&quot;https://zh.wikipedia.org/w/index.php?title=%E6%97%A0%E7%A8%8B%E5%BA%8F%E5%8F%AF%E5%BE%AA%E9%9A%BE%E5%BA%A6&amp;amp;action=edit&amp;amp;redlink=1\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;无程序可循难度\&quot;&gt;无程序可循难度&lt;/a&gt;，所以部分的机器学习研究是开发容易处理的近似算法。”&lt;br&gt;&lt;br&gt;——中文维基百科&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/d3dd87a0feae0a3db82973157eee89c0_is.png&quot;,&quot;name&quot;:&quot;机器学习&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19559450&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机 可以自动“学习 ”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的…&quot;,&quot;id&quot;:&quot;19559450&quot;},{&quot;introduction&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。&lt;br&gt;信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5ce26ec8b_is.jpg&quot;,&quot;name&quot;:&quot;信息论&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19612134&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。 信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;id&quot;:&quot;19612134&quot;}],&quot;excerpt&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;answerCount&quot;:5,&quot;isEditable&quot;:false,&quot;editableDetail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;visitCount&quot;:25804,&quot;id&quot;:41252833,&quot;collapsedAnswerCount&quot;:2,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_{size}.jpg&quot;,&quot;name&quot;:&quot;武器&quot;,&quot;headline&quot;:&quot;人工智障工程师&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;wu-qi-91-22&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/76e37987687dfe7cd32f006f46335190&quot;,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;76e37987687dfe7cd32f006f46335190&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/41252833&quot;,&quot;created&quot;:1457672408,&quot;detail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;updatedTime&quot;:1457672408,&quot;redirection&quot;:{&quot;to&quot;:{},&quot;from&quot;:[]},&quot;commentCount&quot;:0,&quot;questionType&quot;:&quot;normal&quot;,&quot;followerCount&quot;:396,&quot;title&quot;:&quot;如何通俗的解释交叉熵与相对熵?&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;type&quot;:&quot;question&quot;,&quot;isNormal&quot;:true}},&quot;answers&quot;:{&quot;108777563&quot;:{&quot;relationship&quot;:{&quot;upvotedFollowees&quot;:[],&quot;isAuthor&quot;:false,&quot;isNothelp&quot;:false,&quot;isAuthorized&quot;:false,&quot;voting&quot;:0,&quot;isThanked&quot;:false},&quot;editableContent&quot;:&quot;&quot;,&quot;markInfos&quot;:[],&quot;excerpt&quot;:&quot;熵的本质是香农信息量(log\\frac{1}{p} )的期望。 现有关于样本集的2个概率分布p和q，其中p为真实分布，q非真实分布。按照真实分布p来衡量识别一个样本的所需要的编码长度的期望(即平均编码长度)为：H(p)=\\sum_{i}^{} p(i)*log\\frac{1}{p(i)} 。如果使用错误…&quot;,&quot;collapsedBy&quot;:&quot;nobody&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;createdTime&quot;:1467346272,&quot;updatedTime&quot;:1467346435,&quot;id&quot;:108777563,&quot;voteupCount&quot;:270,&quot;collapseReason&quot;:&quot;&quot;,&quot;isCollapsed&quot;:false,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic3.zhimg.com/7cf43c65cbe2780071ed935e569d519e_{size}.jpg&quot;,&quot;name&quot;:&quot;Noriko Oshima&quot;,&quot;headline&quot;:&quot;&quot;,&quot;gender&quot;:0,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;do-cre&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic3.zhimg.com/7cf43c65cbe2780071ed935e569d519e_is.jpg&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/bf5d6529a86a489ae40bec5afe3ba46a&quot;,&quot;type&quot;:&quot;people&quot;,&quot;followerCount&quot;:119,&quot;badge&quot;:[],&quot;id&quot;:&quot;bf5d6529a86a489ae40bec5afe3ba46a&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/answers/108777563&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;question&quot;:{&quot;status&quot;:{&quot;isLocked&quot;:false,&quot;isClose&quot;:false,&quot;isEvaluate&quot;:false,&quot;isSuggest&quot;:false},&quot;relationship&quot;:{&quot;concernedFollowers&quot;:[],&quot;isAnonymous&quot;:false,&quot;canLock&quot;:false,&quot;isFollowing&quot;:false,&quot;isAuthor&quot;:false,&quot;canCollapseAnswers&quot;:false,&quot;canStickAnswers&quot;:false},&quot;isMuted&quot;:false,&quot;topics&quot;:[{&quot;introduction&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/3dc1abe04_is.jpg&quot;,&quot;name&quot;:&quot;数学&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19554091&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;id&quot;:&quot;19554091&quot;},{&quot;introduction&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;计算机\&quot;&gt;计算机&lt;/a&gt;可以自动“&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E5%AD%A6%E4%B9%A0\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;学习\&quot;&gt;学习&lt;/a&gt;”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%AE%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;推论\&quot;&gt;推论&lt;/a&gt;问题属于&lt;a href=\&quot;https://zh.wikipedia.org/w/index.php?title=%E6%97%A0%E7%A8%8B%E5%BA%8F%E5%8F%AF%E5%BE%AA%E9%9A%BE%E5%BA%A6&amp;amp;action=edit&amp;amp;redlink=1\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;无程序可循难度\&quot;&gt;无程序可循难度&lt;/a&gt;，所以部分的机器学习研究是开发容易处理的近似算法。”&lt;br&gt;&lt;br&gt;——中文维基百科&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/d3dd87a0feae0a3db82973157eee89c0_is.png&quot;,&quot;name&quot;:&quot;机器学习&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19559450&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机 可以自动“学习 ”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的…&quot;,&quot;id&quot;:&quot;19559450&quot;},{&quot;introduction&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。&lt;br&gt;信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5ce26ec8b_is.jpg&quot;,&quot;name&quot;:&quot;信息论&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19612134&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。 信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;id&quot;:&quot;19612134&quot;}],&quot;excerpt&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;answerCount&quot;:5,&quot;isEditable&quot;:false,&quot;editableDetail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;visitCount&quot;:25804,&quot;id&quot;:41252833,&quot;collapsedAnswerCount&quot;:2,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_{size}.jpg&quot;,&quot;name&quot;:&quot;武器&quot;,&quot;headline&quot;:&quot;人工智障工程师&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;wu-qi-91-22&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/76e37987687dfe7cd32f006f46335190&quot;,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;76e37987687dfe7cd32f006f46335190&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/41252833&quot;,&quot;created&quot;:1457672408,&quot;detail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;updatedTime&quot;:1457672408,&quot;redirection&quot;:{&quot;to&quot;:{},&quot;from&quot;:[]},&quot;commentCount&quot;:0,&quot;questionType&quot;:&quot;normal&quot;,&quot;followerCount&quot;:396,&quot;title&quot;:&quot;如何通俗的解释交叉熵与相对熵?&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;type&quot;:&quot;question&quot;,&quot;isNormal&quot;:true},&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;url&quot;:&quot;&quot;,&quot;unnormalDetails&quot;:{},&quot;tip&quot;:&quot;&quot;},&quot;content&quot;:&quot;熵的本质是香农信息量(&lt;img src=\&quot;https://www.zhihu.com/equation?tex=log%5Cfrac%7B1%7D%7Bp%7D+\&quot; alt=\&quot;log\\frac{1}{p} \&quot; eeimg=\&quot;1\&quot;&gt;)的期望。&lt;br&gt;&lt;br&gt;现有关于样本集的2个概率分布p和q，其中p为真实分布，q非真实分布。按照真实分布p来衡量识别一个样本的所需要的编码长度的期望(即平均编码长度)为：H(p)=&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Csum_%7Bi%7D%5E%7B%7D+p%28i%29%2Alog%5Cfrac%7B1%7D%7Bp%28i%29%7D+\&quot; alt=\&quot;\\sum_{i}^{} p(i)*log\\frac{1}{p(i)} \&quot; eeimg=\&quot;1\&quot;&gt;。如果使用错误分布q来表示来自真实分布p的平均编码长度，则应该是：H(p,q)=&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Csum_%7Bi%7D%5E%7B%7D+p%28i%29%2Alog%5Cfrac%7B1%7D%7Bq%28i%29%7D+\&quot; alt=\&quot;\\sum_{i}^{} p(i)*log\\frac{1}{q(i)} \&quot; eeimg=\&quot;1\&quot;&gt;。因为用q来编码的样本来自分布p，所以期望H(p,q)中概率是p(i)。H(p,q)我们称之为“交叉熵”。&lt;br&gt;&lt;br&gt;比如含有4个字母(A,B,C,D)的数据集中，真实分布p=(1/2, 1/2, 0, 0)，即A和B出现的概率均为1/2，C和D出现的概率都为0。计算H(p)为1，即只需要1位编码即可识别A和B。如果使用分布Q=(1/4, 1/4, 1/4, 1/4)来编码则得到H(p,q)=2，即需要2位编码来识别A和B(当然还有C和D，尽管C和D并不会出现，因为真实分布p中C和D出现的概率为0，这里就钦定概率为0的事件不会发生啦)。&lt;br&gt;&lt;br&gt;可以看到上例中根据非真实分布q得到的平均编码长度H(p,q)大于根据真实分布p得到的平均编码长度H(p)。事实上，根据&lt;a href=\&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Gibbs%2527_inequality\&quot; class=\&quot; wrap external\&quot; target=\&quot;_blank\&quot; rel=\&quot;nofollow noreferrer\&quot;&gt;Gibbs&#x27; inequality&lt;i class=\&quot;icon-external\&quot;&gt;&lt;/i&gt;&lt;/a&gt;可知，H(p,q)&amp;gt;=H(p)恒成立，当q为真实分布p时取等号。我们将由q得到的平均编码长度比由p得到的平均编码长度多出的bit数称为“相对熵”：D(p||q)=H(p,q)-H(p)=&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Csum_%7Bi%7D%5E%7B%7D+p%28i%29%2Alog%5Cfrac%7Bp%28i%29%7D%7Bq%28i%29%7D+\&quot; alt=\&quot;\\sum_{i}^{} p(i)*log\\frac{p(i)}{q(i)} \&quot; eeimg=\&quot;1\&quot;&gt;，其又被称为KL散度(Kullback–Leibler divergence，KLD) &lt;a href=\&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kullback%25E2%2580%2593Leibler_divergence\&quot; class=\&quot; wrap external\&quot; target=\&quot;_blank\&quot; rel=\&quot;nofollow noreferrer\&quot;&gt;Kullback–Leibler divergence&lt;i class=\&quot;icon-external\&quot;&gt;&lt;/i&gt;&lt;/a&gt;。它表示2个函数或概率分布的差异性：差异越大则相对熵越大，差异越小则相对熵越小，特别地，若2者相同则熵为0。注意，KL散度的非对称性。&lt;br&gt;&lt;br&gt;比如TD-IDF算法就可以理解为相对熵的应用：词频在整个语料库的分布与词频在具体文档中分布之间的差异性。&lt;br&gt;&lt;br&gt;交叉熵可在神经网络(机器学习)中作为损失函数，p表示真实标记的分布，q则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量p与q的相似性。交叉熵作为损失函数还有一个好处是使用sigmoid函数在梯度下降时能避免均方误差损失函数学习速率降低的问题，因为学习速率可以被输出的误差所控制。&lt;br&gt;&lt;br&gt;PS：通常“相对熵”也可称为“交叉熵”，因为真实分布p是固定的，D(p||q)由H(p,q)决定。当然也有特殊情况，彼时2者须区别对待。&quot;,&quot;commentCount&quot;:27,&quot;extras&quot;:&quot;&quot;,&quot;reshipmentSettings&quot;:&quot;allowed&quot;,&quot;isCopyable&quot;:true,&quot;type&quot;:&quot;answer&quot;,&quot;thumbnail&quot;:&quot;&quot;,&quot;isNormal&quot;:true},&quot;140950659&quot;:{&quot;relationship&quot;:{&quot;upvotedFollowees&quot;:[],&quot;isAuthor&quot;:false,&quot;isNothelp&quot;:false,&quot;isAuthorized&quot;:false,&quot;voting&quot;:0,&quot;isThanked&quot;:false},&quot;editableContent&quot;:&quot;&quot;,&quot;markInfos&quot;:[],&quot;excerpt&quot;:&quot;正在学习 DL Book 第6章，查资料看到了这个问题。 受第一个答案启发，自己写了一些笔记。 分享出来供大家参考。有问题欢迎讨论。 ------------------------------------------------------------------------------------------------- 先给结论： 1）信息…&quot;,&quot;collapsedBy&quot;:&quot;nobody&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;createdTime&quot;:1484393609,&quot;updatedTime&quot;:1484449377,&quot;id&quot;:140950659,&quot;voteupCount&quot;:49,&quot;collapseReason&quot;:&quot;&quot;,&quot;isCollapsed&quot;:false,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/v2-9dcf9e7e30c6b2f729322a1632db7e5b_{size}.jpg&quot;,&quot;name&quot;:&quot;张一山&quot;,&quot;headline&quot;:&quot;FPGA / IC for AI&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;zhang-___-shan&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/v2-9dcf9e7e30c6b2f729322a1632db7e5b_is.jpg&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/05ad383eea532d578b2ac53c2007c99c&quot;,&quot;type&quot;:&quot;people&quot;,&quot;followerCount&quot;:151,&quot;badge&quot;:[],&quot;id&quot;:&quot;05ad383eea532d578b2ac53c2007c99c&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/answers/140950659&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;question&quot;:{&quot;status&quot;:{&quot;isLocked&quot;:false,&quot;isClose&quot;:false,&quot;isEvaluate&quot;:false,&quot;isSuggest&quot;:false},&quot;relationship&quot;:{&quot;concernedFollowers&quot;:[],&quot;isAnonymous&quot;:false,&quot;canLock&quot;:false,&quot;isFollowing&quot;:false,&quot;isAuthor&quot;:false,&quot;canCollapseAnswers&quot;:false,&quot;canStickAnswers&quot;:false},&quot;isMuted&quot;:false,&quot;topics&quot;:[{&quot;introduction&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/3dc1abe04_is.jpg&quot;,&quot;name&quot;:&quot;数学&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19554091&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;id&quot;:&quot;19554091&quot;},{&quot;introduction&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;计算机\&quot;&gt;计算机&lt;/a&gt;可以自动“&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E5%AD%A6%E4%B9%A0\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;学习\&quot;&gt;学习&lt;/a&gt;”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%AE%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;推论\&quot;&gt;推论&lt;/a&gt;问题属于&lt;a href=\&quot;https://zh.wikipedia.org/w/index.php?title=%E6%97%A0%E7%A8%8B%E5%BA%8F%E5%8F%AF%E5%BE%AA%E9%9A%BE%E5%BA%A6&amp;amp;action=edit&amp;amp;redlink=1\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;无程序可循难度\&quot;&gt;无程序可循难度&lt;/a&gt;，所以部分的机器学习研究是开发容易处理的近似算法。”&lt;br&gt;&lt;br&gt;——中文维基百科&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/d3dd87a0feae0a3db82973157eee89c0_is.png&quot;,&quot;name&quot;:&quot;机器学习&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19559450&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机 可以自动“学习 ”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的…&quot;,&quot;id&quot;:&quot;19559450&quot;},{&quot;introduction&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。&lt;br&gt;信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5ce26ec8b_is.jpg&quot;,&quot;name&quot;:&quot;信息论&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19612134&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。 信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;id&quot;:&quot;19612134&quot;}],&quot;excerpt&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;answerCount&quot;:5,&quot;isEditable&quot;:false,&quot;editableDetail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;visitCount&quot;:25804,&quot;id&quot;:41252833,&quot;collapsedAnswerCount&quot;:2,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_{size}.jpg&quot;,&quot;name&quot;:&quot;武器&quot;,&quot;headline&quot;:&quot;人工智障工程师&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;wu-qi-91-22&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/76e37987687dfe7cd32f006f46335190&quot;,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;76e37987687dfe7cd32f006f46335190&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/41252833&quot;,&quot;created&quot;:1457672408,&quot;detail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;updatedTime&quot;:1457672408,&quot;redirection&quot;:{&quot;to&quot;:{},&quot;from&quot;:[]},&quot;commentCount&quot;:0,&quot;questionType&quot;:&quot;normal&quot;,&quot;followerCount&quot;:396,&quot;title&quot;:&quot;如何通俗的解释交叉熵与相对熵?&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;type&quot;:&quot;question&quot;,&quot;isNormal&quot;:true},&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;url&quot;:&quot;&quot;,&quot;unnormalDetails&quot;:{},&quot;tip&quot;:&quot;&quot;},&quot;content&quot;:&quot;正在学习 DL Book 第6章，查资料看到了这个问题。&lt;br&gt;受第一个答案启发，自己写了一些笔记。&lt;br&gt;分享出来供大家参考。有问题欢迎讨论。&lt;br&gt;-------------------------------------------------------------------------------------------------&lt;br&gt;先给结论：&lt;br&gt;1）信息熵：编码方案完美时，最短平均编码长度的是多少。&lt;br&gt;2）交叉熵：编码方案不一定完美时（由于对概率分布的估计不一定正确），平均编码长度的是多少。&lt;br&gt;              平均编码长度 = 最短平均编码长度 + 一个增量&lt;br&gt;3）相对熵：编码方案不一定完美时，平均编码长度相对于最小值的增加值。（即上面那个增量）&lt;br&gt;-------------------------------------------------------------------------------------------------&lt;br&gt;&lt;br&gt;零、信息熵&lt;br&gt;1、熵的本质是&lt;u&gt;&lt;b&gt;香农&lt;/b&gt;&lt;b&gt;信息量 log(1/p) 的期望&lt;/b&gt;&lt;/u&gt;；（参考了第一个答案）&lt;br&gt;      H(p) = E[ log(1/p) ] = ∑ p_i * log(1/p_i)，是一个期望的计算，也是记录随机事件结果的平均编码长度；&lt;br&gt;        为什么信息量 是 log(1/p) 呢？&lt;br&gt;        因为：一个事件结果的出现概率越低，对其编码的bit长度就越长。&lt;br&gt;                  以期在整个随机事件的无数次重复试验中，用最少的 bit 去记录整个实验历史。&lt;br&gt;                  即无法压缩的表达，代表了真正的信息量。&lt;br&gt;&lt;br&gt;2、熵的本质的另一种解释：&lt;b&gt;&lt;u&gt;最短平均编码长度&lt;/u&gt;&lt;/b&gt;；&lt;br&gt;    【本质含义：编码方案完美时，最短平均编码长度的是多少】&lt;br&gt;&lt;br&gt;3、&lt;b&gt;&lt;u&gt;交叉熵&lt;/u&gt;&lt;/b&gt;，则可以这样理解：&lt;b&gt;&lt;u&gt;使用了“估算”的编码后，得到的平均编码长度&lt;/u&gt;&lt;/b&gt;（可能不是最短的）&lt;br&gt;            p是真实概率分布，q是你以为的概率分布（可能不一致）；&lt;br&gt;            你以 q 去编码，编码方案 log(1/q_i)可能不是最优的；&lt;br&gt;            于是，平均编码长度 = ∑ p_i *log(1/q_i)，就是交叉熵；&lt;br&gt;            只有在估算的分布 q 完全正确时，平均编码长度才是最短的，交叉熵 = 熵&lt;br&gt;&lt;br&gt;&lt;br&gt;一、交叉熵&lt;br&gt;1、定义&lt;br&gt;    【本质含义：编码方案不一定完美时，平均编码长度的是多少】&lt;br&gt;    连续函数：&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic3.zhimg.com/v2-7d4806737924e1d69087a212ab9383a2_b.png\&quot; data-rawwidth=\&quot;312\&quot; data-rawheight=\&quot;32\&quot; class=\&quot;content_image\&quot; width=\&quot;312\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;312\&quot; data-rawheight=\&quot;32\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;312\&quot; data-actualsrc=\&quot;https://pic3.zhimg.com/v2-7d4806737924e1d69087a212ab9383a2_b.png\&quot;&gt;&lt;br&gt;            两项中 H(p)是 p的信息熵，后者是相对熵；&lt;br&gt;    离散函数：&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic4.zhimg.com/v2-a064eab677bb964913f0d156c028d0fb_b.png\&quot; data-rawwidth=\&quot;216\&quot; data-rawheight=\&quot;44\&quot; class=\&quot;content_image\&quot; width=\&quot;216\&quot;&gt;=Entropy(P) + D_KL(P||Q)&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;216\&quot; data-rawheight=\&quot;44\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;216\&quot; data-actualsrc=\&quot;https://pic4.zhimg.com/v2-a064eab677bb964913f0d156c028d0fb_b.png\&quot;&gt;=Entropy(P) + D_KL(P||Q)&lt;br&gt;&lt;br&gt;2、在 ML 中等效于相对熵&lt;br&gt;    【作用：用来评估，当前训练得到的概率分布，与真实分布有多么大的差异】&lt;br&gt;        因为与相对熵只差一个 分布 P 的信息熵，&lt;br&gt;        若 P 是固定的分布，与训练无关；&lt;br&gt;        Q 是估计的分布，应尽量等于 P。&lt;br&gt;        二者一致时，交叉熵就等于 P 的熵&lt;br&gt;&lt;br&gt;二、相对熵&lt;br&gt;    【本质含义：由于编码方案不一定完美，导致的平均编码长度的增大值】&lt;br&gt;    离散：&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic3.zhimg.com/v2-a1d7ca22685d59521b063a5cf0599df6_b.png\&quot; data-rawwidth=\&quot;237\&quot; data-rawheight=\&quot;52\&quot; class=\&quot;content_image\&quot; width=\&quot;237\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;237\&quot; data-rawheight=\&quot;52\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;237\&quot; data-actualsrc=\&quot;https://pic3.zhimg.com/v2-a1d7ca22685d59521b063a5cf0599df6_b.png\&quot;&gt;&lt;br&gt;        【发现：D_KL(P||Q) = ∑P(i) *logP(i) - ∑P(i) *logQ(i) &lt;br&gt;                                    = - Entropy(P) + 交叉熵 H(p,q) 】&lt;br&gt;    连续：&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic1.zhimg.com/v2-773d21115b182b6f6658dea8087ab8a8_b.png\&quot; data-rawwidth=\&quot;264\&quot; data-rawheight=\&quot;56\&quot; class=\&quot;content_image\&quot; width=\&quot;264\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;264\&quot; data-rawheight=\&quot;56\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;264\&quot; data-actualsrc=\&quot;https://pic1.zhimg.com/v2-773d21115b182b6f6658dea8087ab8a8_b.png\&quot;&gt;&lt;br&gt;    1）用来衡量2个取值为正数的函数的相似性&lt;br&gt;    2）2个完全相同的函数，相对熵为0；差异越大，相对熵越大；&lt;br&gt;    3）概率分布函数，或 概率密度函数，若函数值均大于0，相对熵可以度量两个随机分布的差异性；&lt;br&gt;    4）相对熵不对称，没有交换律&lt;br&gt;&lt;br&gt;&lt;br&gt;-----------------------------------------------------------&lt;br&gt;参考：&lt;br&gt;《数学之美》吴军&lt;br&gt;wiki&lt;br&gt;第一个高票答案&quot;,&quot;commentCount&quot;:5,&quot;extras&quot;:&quot;&quot;,&quot;reshipmentSettings&quot;:&quot;allowed&quot;,&quot;isCopyable&quot;:true,&quot;type&quot;:&quot;answer&quot;,&quot;thumbnail&quot;:&quot;&quot;,&quot;isNormal&quot;:true},&quot;141598211&quot;:{&quot;relationship&quot;:{&quot;upvotedFollowees&quot;:[],&quot;isAuthor&quot;:false,&quot;isNothelp&quot;:false,&quot;isAuthorized&quot;:false,&quot;voting&quot;:0,&quot;isThanked&quot;:false},&quot;editableContent&quot;:&quot;&quot;,&quot;markInfos&quot;:[],&quot;excerpt&quot;:&quot;仅从机器学习的角度讨论这个问题。&lt;b&gt;相对熵（relative entropy）&lt;/b&gt;就是KL散度（Kullback–Leibler divergence），用于衡量两个概率分布之间的差异。对于两个概率分布p(x)和q(x) ，其相对熵的计算公式为：\\tt KL\\it(p\\parallel q)=-\\int p(x)\\ln q(x) dx -(-\\int…&quot;,&quot;collapsedBy&quot;:&quot;nobody&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;createdTime&quot;:1484729048,&quot;updatedTime&quot;:1484734564,&quot;id&quot;:141598211,&quot;voteupCount&quot;:27,&quot;collapseReason&quot;:&quot;&quot;,&quot;isCollapsed&quot;:false,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic2.zhimg.com/648cadddeccb1697f74af886d1838e69_{size}.jpg&quot;,&quot;name&quot;:&quot;Agenter&quot;,&quot;headline&quot;:&quot;图像视觉算法和美剧爱好者&quot;,&quot;gender&quot;:-1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;xing-xiao-xiao-33&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic2.zhimg.com/648cadddeccb1697f74af886d1838e69_is.jpg&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/1eb9c597f4d5bd39d1d9af5faee4945e&quot;,&quot;type&quot;:&quot;people&quot;,&quot;followerCount&quot;:14,&quot;badge&quot;:[],&quot;id&quot;:&quot;1eb9c597f4d5bd39d1d9af5faee4945e&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/answers/141598211&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;question&quot;:{&quot;status&quot;:{&quot;isLocked&quot;:false,&quot;isClose&quot;:false,&quot;isEvaluate&quot;:false,&quot;isSuggest&quot;:false},&quot;relationship&quot;:{&quot;concernedFollowers&quot;:[],&quot;isAnonymous&quot;:false,&quot;canLock&quot;:false,&quot;isFollowing&quot;:false,&quot;isAuthor&quot;:false,&quot;canCollapseAnswers&quot;:false,&quot;canStickAnswers&quot;:false},&quot;isMuted&quot;:false,&quot;topics&quot;:[{&quot;introduction&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/3dc1abe04_is.jpg&quot;,&quot;name&quot;:&quot;数学&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19554091&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;数学是关于数量、结构、变化等主题的探索。&quot;,&quot;id&quot;:&quot;19554091&quot;},{&quot;introduction&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;计算机\&quot;&gt;计算机&lt;/a&gt;可以自动“&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E5%AD%A6%E4%B9%A0\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;学习\&quot;&gt;学习&lt;/a&gt;”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多&lt;a href=\&quot;https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%AE%BA\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;推论\&quot;&gt;推论&lt;/a&gt;问题属于&lt;a href=\&quot;https://zh.wikipedia.org/w/index.php?title=%E6%97%A0%E7%A8%8B%E5%BA%8F%E5%8F%AF%E5%BE%AA%E9%9A%BE%E5%BA%A6&amp;amp;action=edit&amp;amp;redlink=1\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;无程序可循难度\&quot;&gt;无程序可循难度&lt;/a&gt;，所以部分的机器学习研究是开发容易处理的近似算法。”&lt;br&gt;&lt;br&gt;——中文维基百科&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/d3dd87a0feae0a3db82973157eee89c0_is.png&quot;,&quot;name&quot;:&quot;机器学习&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19559450&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机 可以自动“学习 ”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的…&quot;,&quot;id&quot;:&quot;19559450&quot;},{&quot;introduction&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。&lt;br&gt;信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5ce26ec8b_is.jpg&quot;,&quot;name&quot;:&quot;信息论&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19612134&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;信息论（英语：information theory）是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。 信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信道编码定理、信源－信道隔离定理相互联系。&quot;,&quot;id&quot;:&quot;19612134&quot;}],&quot;excerpt&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;answerCount&quot;:5,&quot;isEditable&quot;:false,&quot;editableDetail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;visitCount&quot;:25804,&quot;id&quot;:41252833,&quot;collapsedAnswerCount&quot;:2,&quot;author&quot;:{&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_{size}.jpg&quot;,&quot;name&quot;:&quot;武器&quot;,&quot;headline&quot;:&quot;人工智障工程师&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;wu-qi-91-22&quot;,&quot;isAdvertiser&quot;:false,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/89d358811d103aab396e75bbc57b4067_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/76e37987687dfe7cd32f006f46335190&quot;,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;76e37987687dfe7cd32f006f46335190&quot;,&quot;isOrg&quot;:false},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/41252833&quot;,&quot;created&quot;:1457672408,&quot;detail&quot;:&quot;如题。 信息论中的条件熵，联合熵等比较好理解，物理意义也相对明确。请问有人能以相对通俗的语言解释『交叉熵』与『相对熵』动机与含义吗？&quot;,&quot;updatedTime&quot;:1457672408,&quot;redirection&quot;:{&quot;to&quot;:{},&quot;from&quot;:[]},&quot;commentCount&quot;:0,&quot;questionType&quot;:&quot;normal&quot;,&quot;followerCount&quot;:396,&quot;title&quot;:&quot;如何通俗的解释交叉熵与相对熵?&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;type&quot;:&quot;question&quot;,&quot;isNormal&quot;:true},&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;url&quot;:&quot;&quot;,&quot;unnormalDetails&quot;:{},&quot;tip&quot;:&quot;&quot;},&quot;content&quot;:&quot;&lt;p&gt;仅从机器学习的角度讨论这个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;相对熵（relative entropy）&lt;/b&gt;就是KL散度（Kullback–Leibler divergence），用于衡量两个概率分布之间的差异。&lt;/p&gt;&lt;p&gt;对于两个概率分布&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28x%29\&quot; alt=\&quot;p(x)\&quot; eeimg=\&quot;1\&quot;&gt;和&lt;img src=\&quot;https://www.zhihu.com/equation?tex=q%28x%29\&quot; alt=\&quot;q(x)\&quot; eeimg=\&quot;1\&quot;&gt; ，其相对熵的计算公式为：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Ctt+KL%5Cit%28p%5Cparallel+q%29%3D-%5Cint+p%28x%29%5Cln+q%28x%29+dx+-%28-%5Cint+p%28x%29%5Cln+p%28x%29+dx%29\&quot; alt=\&quot;\\tt KL\\it(p\\parallel q)=-\\int p(x)\\ln q(x) dx -(-\\int p(x)\\ln p(x) dx)\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;注意：由于&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28x%29\&quot; alt=\&quot;p(x)\&quot; eeimg=\&quot;1\&quot;&gt; 和&lt;img src=\&quot;https://www.zhihu.com/equation?tex=q%28x%29\&quot; alt=\&quot;q(x)\&quot; eeimg=\&quot;1\&quot;&gt; 在公式中的地位不是相等的，所以&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Ctt+KL+%5Cit%28p%5Cparallel+q%29%5Cnot%5Cequiv+%5Ctt+KL+%5Cit+%28q%5Cparallel+p%29\&quot; alt=\&quot;\\tt KL \\it(p\\parallel q)\\not\\equiv \\tt KL \\it (q\\parallel p)\&quot; eeimg=\&quot;1\&quot;&gt;.&lt;/p&gt;&lt;p&gt;相对熵的特点，是只有&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28x%29%3Dq%28x%29\&quot; alt=\&quot;p(x)=q(x)\&quot; eeimg=\&quot;1\&quot;&gt; 时，其值为0。若&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28x%29\&quot; alt=\&quot;p(x)\&quot; eeimg=\&quot;1\&quot;&gt; 和&lt;img src=\&quot;https://www.zhihu.com/equation?tex=q%28x%29\&quot; alt=\&quot;q(x)\&quot; eeimg=\&quot;1\&quot;&gt; 略有差异，其值就会大于0。其证明利用了负对数函数（&lt;img src=\&quot;https://www.zhihu.com/equation?tex=-%5Cln+x\&quot; alt=\&quot;-\\ln x\&quot; eeimg=\&quot;1\&quot;&gt; ）是严格凸函数（strictly convex function）的性质。具体可以参考&lt;i&gt;PRML&lt;/i&gt; 1.6.1 Relative entropy and mutual information.&lt;/p&gt;&lt;p&gt;相对熵公式的前半部分&lt;img src=\&quot;https://www.zhihu.com/equation?tex=-%5Cint+p%28x%29%5Cln+q%28x%29dx\&quot; alt=\&quot;-\\int p(x)\\ln q(x)dx\&quot; eeimg=\&quot;1\&quot;&gt; 就是&lt;b&gt;交叉熵（cross entropy）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;若&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28x%29\&quot; alt=\&quot;p(x)\&quot; eeimg=\&quot;1\&quot;&gt; 是数据的真实概率分布，&lt;img src=\&quot;https://www.zhihu.com/equation?tex=q%28x%29\&quot; alt=\&quot;q(x)\&quot; eeimg=\&quot;1\&quot;&gt; 是由数据计算得到的概率分布。机器学习的目的就是希望&lt;img src=\&quot;https://www.zhihu.com/equation?tex=q%28x%29\&quot; alt=\&quot;q(x)\&quot; eeimg=\&quot;1\&quot;&gt;尽可能地逼近甚至等于&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28x%29\&quot; alt=\&quot;p(x)\&quot; eeimg=\&quot;1\&quot;&gt; ，从而使得相对熵接近最小值0. 由于真实的概率分布是固定的，相对熵公式的后半部分&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%28-%5Cint+p%28x%29%5Cln+p%28x%29+dx%29\&quot; alt=\&quot;(-\\int p(x)\\ln p(x) dx)\&quot; eeimg=\&quot;1\&quot;&gt; 就成了一个常数。那么相对熵达到最小值的时候，也意味着交叉熵达到了最小值。对&lt;img src=\&quot;https://www.zhihu.com/equation?tex=q%28x%29\&quot; alt=\&quot;q(x)\&quot; eeimg=\&quot;1\&quot;&gt; 的优化就等效于求交叉熵的最小值。另外，对交叉熵求最小值，也等效于求最大似然估计（maximum likelihood estimation）。具体可以参考&lt;i&gt;Deep Learning&lt;/i&gt; 5.5 Maximum Likelihood Estimation.&lt;/p&gt;&quot;,&quot;commentCount&quot;:1,&quot;extras&quot;:&quot;&quot;,&quot;reshipmentSettings&quot;:&quot;allowed&quot;,&quot;isCopyable&quot;:true,&quot;type&quot;:&quot;answer&quot;,&quot;thumbnail&quot;:&quot;&quot;,&quot;isNormal&quot;:true}},&quot;articles&quot;:{},&quot;columns&quot;:{},&quot;topics&quot;:{},&quot;roundtables&quot;:{},&quot;favlists&quot;:{},&quot;comments&quot;:{},&quot;notifications&quot;:{},&quot;ebooks&quot;:{},&quot;activities&quot;:{},&quot;feeds&quot;:{}},&quot;currentUser&quot;:&quot;houkaijun&quot;,&quot;token&quot;:{&quot;carCompose&quot;:&quot;2|1:0|10:1498458316|4:SZYUpkoc0tvYXh0V2E2UTBUID096dwe|92:Mi4wQUJES2NQYXZjUWtBQU1BRnA2eWtDU1lBQUFCZ0FsVk56RFY0V1FCZGdTWkRSS3FNa210TUhWczJ5MlYzeHp1X3p3|ed606fbb5e5532b2d41149b1ef90871d2e9f011f8ffdec5064d21305e5baa08f&quot;,&quot;xUDID&quot;:&quot;AADABaespAmPTgMeSeEt8ie9r6bHV-Kt2P4=&quot;},&quot;account&quot;:{&quot;locakTicketStatus&quot;:false,&quot;challenge&quot;:[],&quot;errorStatus&quot;:false,&quot;message&quot;:&quot;&quot;,&quot;isFetching&quot;:false},&quot;notification&quot;:{},&quot;cookie&quot;:&quot;&quot;,&quot;people&quot;:{&quot;isFetching&quot;:false,&quot;activitiesByUser&quot;:{},&quot;answersByUser&quot;:{},&quot;answersSortByVotesByUser&quot;:{},&quot;answersMarkedByUser&quot;:{},&quot;votedAnswersByUser&quot;:{},&quot;thankedAnswersByUser&quot;:{},&quot;voteAnswersByUser&quot;:{},&quot;thankAnswersByUser&quot;:{},&quot;topicAnswersByUser&quot;:{},&quot;articlesByUser&quot;:{},&quot;articlesSortByVotesByUser&quot;:{},&quot;pinsByUser&quot;:{},&quot;questionsByUser&quot;:{},&quot;commercialQuestionsByUser&quot;:{},&quot;favlistsByUser&quot;:{},&quot;followingByUser&quot;:{},&quot;followersByUser&quot;:{},&quot;mutualsByUser&quot;:{},&quot;followingColumnsByUser&quot;:{},&quot;followingQuestionsByUser&quot;:{},&quot;followingFavlistsByUser&quot;:{},&quot;followingTopicsByUser&quot;:{},&quot;publicationsByUser&quot;:{},&quot;columnsByUser&quot;:{},&quot;allFavlistsByUser&quot;:{},&quot;brands&quot;:null},&quot;env&quot;:{&quot;experiment&quot;:{&quot;topnavbarQrcode&quot;:&quot;topnavbar_qrcode_show&quot;,&quot;ge2&quot;:&quot;ge2_1&quot;,&quot;nwebStickySidebar&quot;:&quot;sticky&quot;,&quot;homeNweb&quot;:&quot;f1&quot;,&quot;ge3&quot;:&quot;ge3_9&quot;,&quot;favAct&quot;:&quot;default&quot;,&quot;default&quot;:&quot;None&quot;,&quot;newMore&quot;:&quot;new&quot;,&quot;recommendReadingsOnShare&quot;:&quot;wx_share_editor_recommend&quot;,&quot;wechatShareModal&quot;:&quot;wechat_share_modal_show&quot;,&quot;qaStickySidebar&quot;:&quot;sticky_sidebar&quot;,&quot;liveStore&quot;:&quot;ls_a3_b2_c2_f2&quot;,&quot;zcmLighting&quot;:&quot;zcm&quot;},&quot;userAgent&quot;:{&quot;Edge&quot;:false,&quot;Wechat&quot;:false,&quot;Weibo&quot;:false,&quot;QQ&quot;:false,&quot;Mobile&quot;:false,&quot;Android&quot;:false,&quot;iOS&quot;:false,&quot;isAppleDevice&quot;:true,&quot;Zhihu&quot;:false,&quot;isBot&quot;:false,&quot;isWebView&quot;:false},&quot;trafficSource&quot;:&quot;&quot;},&quot;config&quot;:{&quot;windowEndAt&quot;:&quot;2017-06-22T16:00:00.000Z&quot;,&quot;canWrite&quot;:true,&quot;alertTimeSpan&quot;:3600,&quot;tip&quot;:&quot;应国家法规对于帐号实名的要求，进行下一步操作前，需要先完成手机绑定。&quot;},&quot;pushNotifications&quot;:{&quot;default&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[]},&quot;follow&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[]},&quot;vote-thank&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[]},&quot;currentTab&quot;:&quot;default&quot;,&quot;notificationsCount&quot;:{&quot;default&quot;:0,&quot;follow&quot;:0,&quot;vote-thank&quot;:0}},&quot;messages&quot;:{&quot;data&quot;:{},&quot;currentTab&quot;:&quot;common&quot;,&quot;messageCount&quot;:0},&quot;register&quot;:{&quot;registerValidateSucceeded&quot;:null,&quot;registerValidateErrors&quot;:{},&quot;registerConfirmError&quot;:null,&quot;sendDigitsError&quot;:null,&quot;registerConfirmSucceeded&quot;:null},&quot;login&quot;:{&quot;loginConfirmError&quot;:null,&quot;sendDigitsError&quot;:null,&quot;loginConfirmSucceeded&quot;:null,&quot;qrcodeLoginToken&quot;:&quot;&quot;,&quot;qrcodeLoginScanStatus&quot;:0,&quot;qrcodeLoginError&quot;:null,&quot;qrcodeLoginReturnNewToken&quot;:false},&quot;active&quot;:{&quot;sendDigitsError&quot;:null,&quot;activeConfirmSucceeded&quot;:null,&quot;activeConfirmError&quot;:null},&quot;question&quot;:{&quot;followers&quot;:{},&quot;concernedFollowers&quot;:{},&quot;answers&quot;:{&quot;41252833&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[108777563,141598211,140950659],&quot;newIds&quot;:[108777563,141598211,140950659],&quot;totals&quot;:5,&quot;isPrevDrained&quot;:true,&quot;previous&quot;:&quot;http://www.zhihu.com/api/v4/questions/41252833/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=3&amp;offset=0&quot;,&quot;next&quot;:&quot;http://www.zhihu.com/api/v4/questions/41252833/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=3&amp;offset=3&quot;}},&quot;hiddenAnswers&quot;:{},&quot;createdAnswers&quot;:{},&quot;collapsedAnswers&quot;:{},&quot;notificationAnswers&quot;:{},&quot;invitationCandidates&quot;:{},&quot;inviters&quot;:{},&quot;invitees&quot;:{},&quot;similarQuestions&quot;:{},&quot;relatedLives&quot;:{},&quot;bio&quot;:{},&quot;brand&quot;:{},&quot;commonAnswerCount&quot;:0,&quot;hiddenAnswerCount&quot;:0},&quot;comments&quot;:{&quot;pagination&quot;:{},&quot;reverse&quot;:{},&quot;reviewing&quot;:{},&quot;conversation&quot;:{},&quot;parent&quot;:{}},&quot;shareTexts&quot;:{},&quot;answers&quot;:{&quot;voters&quot;:{},&quot;copyrightApplicants&quot;:{},&quot;favlists&quot;:{},&quot;newAnswer&quot;:{}},&quot;banner&quot;:{},&quot;topics&quot;:{&quot;bios&quot;:{}},&quot;captcha&quot;:{&quot;captchaNeeded&quot;:false,&quot;captchaBase64String&quot;:null,&quot;captchaValidationMessage&quot;:null,&quot;loginCaptchaExpires&quot;:false},&quot;sms&quot;:{&quot;supportedCountries&quot;:[]},&quot;explore&quot;:{&quot;recommendations&quot;:{}},&quot;articles&quot;:{&quot;voters&quot;:{}},&quot;favlists&quot;:{&quot;relations&quot;:{}},&quot;pins&quot;:{&quot;voters&quot;:{}},&quot;topstory&quot;:{&quot;topstorys&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;afterId&quot;:0,&quot;items&quot;:[],&quot;next&quot;:null},&quot;sidebar&quot;:{&quot;isFetching&quot;:false}},&quot;upload&quot;:{},&quot;video&quot;:{&quot;data&quot;:{}},&quot;guide&quot;:{&quot;guide&quot;:{&quot;isFetching&quot;:false,&quot;isShowGuide&quot;:false}},&quot;switches&quot;:{},&quot;coupon&quot;:{&quot;isRedeemingCoupon&quot;:false}}" data-config="{&quot;apiAddress&quot;:&quot;https://www.zhihu.com/api/v4/&quot;,&quot;filterPrefixArray&quot;:[&quot;v3&quot;],&quot;deployEnv&quot;:&quot;production&quot;}" data-reactid="20"></div><script src="https://static.zhihu.com/heifetz/vendor.9de2bffb7477d187bcfb.js" data-reactid="21"></script><script src="https://static.zhihu.com/heifetz/main.raven.5fdec11691b9dd4a5c24.js" async="" data-reactid="22"></script><script src="https://static.zhihu.com/heifetz/main.app.d30e2c0589d673f72a2f.js" data-reactid="23"></script></body></html>